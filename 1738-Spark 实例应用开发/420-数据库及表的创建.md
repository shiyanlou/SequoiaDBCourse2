---
show: step
version: 1.0 
---

## 课程介绍

本课程将介绍如何通过 JDBC 在 Spark SQL 中创建数据库，以及在 Spark SQL 中对已有 SequoiaDB 集合进行映射并访问 SequoiaDB 集合数据。

#### 请点击右侧选择使用的实验环境

#### 部署架构

本课程中 SequoiaDB 巨杉数据库的集群拓扑结构为三分区单副本，其中包括：

* 1 个 SequoiaSQL-MySQL 数据库实例节点
* 1 个引擎协调节点
* 1 个编目节点
* 3 个数据节点

![1738-410-06](https://doc.shiyanlou.com/courses/1738/1207281/ff2754d609aba12340efeb27ce0645bb-0)

在当前实验的部署架构中，Spark 通过 MySQL 实例间接访问 SequoiaDB 存储集群，也可以通过 SequoiaDB 的 Spark 连接驱动直接访问底层的 SequoiaDB 存储集群。

详细了解 SequoiaDB 巨杉数据库系统架构：

* [SequoiaDB 系统架构](http://doc.sequoiadb.com/cn/sequoiadb-cat_id-1519649201-edition_id-0)

#### 实验环境

课程使用的系统环境为 Ubuntu 16.04.6 LTS 版本。SequoiaDB 数据库引擎以及 SequoiaSQL-MySQL 实例均为 3.4 版本。Spark 计算引擎为 2.4.3 版本。

## 打开项目

#### 打开 IDEA

1）打开 IDEA 代码开发工具。

![1738-410-07](https://doc.shiyanlou.com/courses/1738/1207281/72397a857808ab74f01b042f07ea0a27-0)

#### 打开 SCDD-Spark 项目

2）打开 Spark 实验的项目，在该项目中完成所有实验步骤。

![1738-410-08](https://doc.shiyanlou.com/courses/1738/1207281/5497d93bf19ee0442b4ae79b4cd8d39a-0)

#### Maven 依赖

实验环境中已经在 Maven 本地仓库添加了实验所需的依赖。当前实验使用到的 jar 包依赖以及依赖说明如下：

* hive-jdbc-1.2.1.spark.jar

  用于在 Java 程序中通过 JDBC 访问 Spark SQL

* spark-sequoiadb_2.11-3.2.4.jar

  用于在 Spark SQL 中创建 SequoiaDB 集合的映射

* mysql-connector-java-5.1.47.jar

  用于在 Java 程序中通过 JDBC 访问 MySQL 实例

* ibatis2-common-2.1.7.597.jar

  调用 ScriptRunner 执行 sql 文件写入 MySQL 实例，以此初始化 SequoiaDB 集合中的数据

pom.xml 文件位置：

![1738-410-pom文件位置](https://doc.shiyanlou.com/courses/1738/1207281/822fa966b397b80c9eabbf0472eb52c4-0)

当前实验中使用到的 Maven 依赖如下：

![1738-410-maven1](https://doc.shiyanlou.com/courses/1738/1207281/b0f437f18a0a276bbf404da17fef9a2c-0)

![1738-410-maven2](https://doc.shiyanlou.com/courses/1738/1207281/0b93cf135364f978faeba469c3cca528-0)

![1738-420-maven3](https://doc.shiyanlou.com/courses/1738/1207281/fd8e22c3304df6f328663a8b30b0c423-0)

![1738-420-maven4](https://doc.shiyanlou.com/courses/1738/1207281/e262833f73a5b167d89ba087e930642d-0)

> **说明**
>
> spark-sequoiadb_2.11-3.2.4.jar 可以在 [SequoiaDB 巨杉数据库下载中心](http://download.sequoiadb.com/cn/driver) 获取。

#### 打开当前实验的 Package

3）如图所示找到当前实验程序所在 Package，在该 Package 中完成后续实验步骤：

![1738-420-打开package](https://doc.shiyanlou.com/courses/1738/1207281/e74f2b06835fb958d00666e18c1c145e-0)

## 初始化 SequoiaDB 数据

#### 概述

实验环境中 MySQL 实例默认的存储引擎为 SequoiaDB，可以通过在 MySQL 实例中创建表初始化 SequoiaDB 中的数据。程序中将使用 MySQL JDBC 连接驱动创建 JDBC 连接，使用 MySQL JDBC 连接创建 ScriptRunner 执行 sql 文件写入数据，以此来初始化 SequoiaDB 集合。

#### 操作步骤

1）打开 InitSource 类。

![1738-420-打开InitSource](https://doc.shiyanlou.com/courses/1738/1207281/04bc4027500468d64b978b7f92b90fbc-0)

2）复制程序代码。程序中会创建 MySQL JDBC 连接，并使用该连接创建 ScriptRunner 对象，调用 ScriptRunner 执行 sql 文件写入数据后，查询数据将结果集打印到控制台，最终关闭 JDBC 连接资源。为了更简洁地展示代码内容，程序中将异常抛出。

```java
// Load MySQL JDBC Driver class
Class.forName("com.mysql.jdbc.Driver");
// Create MySQL connection
Connection connection = DriverManager.getConnection(
        "jdbc:mysql://sdbserver1:3306/sample?useSSL=false",
        "sdbadmin",
        "sdbadmin");
// Create ScriptRunner
ScriptRunner runner = new ScriptRunner(connection, false, false);
// Turn off log printing
runner.setLogWriter(null);
// Execute sql file via ScriptRunner
runner.runScript(FileUtil.getFile("src/main/resources/sql/employee.sql"));
// Close connection
Statement statement = connection.createStatement();
// Query result set
ResultSet resultSet = statement.executeQuery("SELECT * FROM employee");
// Call the predefined result set to beautify the utility class and print the result set
ResultFormat.printResultSet(resultSet);
// Close ResultSet
resultSet.close();
// Close Statement
statement.close();
// Close Connection
connection.close();
```

> **说明**
>
> ResultFormat 工具类为已经封装好的查询结果集打印类，用于美化结果集的打印。封装的工具类在此不做赘述。

3）将代码粘贴至 InitSource 类 initSourceTable 方法的 TODO code 1 注释区间内。

![1738-420-TODO1](https://doc.shiyanlou.com/courses/1738/1207281/f725cac82de83f4f66f77b7e2d61588f-0)

代码块粘贴完毕后，完整代码如图所示：

![1738-420-DONE1](https://doc.shiyanlou.com/courses/1738/1207281/e3b7a3af3373308056d78ef4a5a67b08-0)

4）右键点击 CreateTableMainTest 类，选择 Create/Edit CreateTableMainTest.main() 编辑主函数参数。

![1738-420-选择编辑1](https://doc.shiyanlou.com/courses/1738/1207281/42f8e64a41e4b3adc95642ed023cb0e1-0)

5）编辑主函数参数为 initSourcetable。

![1738-420-编辑参数1](https://doc.shiyanlou.com/courses/1738/1207281/551a89e6f148ac1508d314a4a0246937-0)

6）右键点击 CreateTableMainTest 类，选择 Run CreateTableMainTest.main() 运行程序。

![1738-420-运行1](https://doc.shiyanlou.com/courses/1738/1207281/01d549fa820dc82a23e92b751f597384-0)

7）查看运行结果。

![1738-420-结果1](https://doc.shiyanlou.com/courses/1738/1207281/1957eb6c81c543a6546efa8e6a768294-0)

## Spark SQL 建库

#### 概述

Spark 的 Hive 中初始只有 default 库，可以通过 Hive JDBC 提交创建数据库语句自定义数据库。当前实验样例中将先创建获取 JDBC 连接和释放 JDBC 资源的代码以便后续的实验步骤中调用，并通过 JDBC 提交创建数据库语句创建数据库。

#### 操作步骤

1）打开 CreateTable 类。

![1738-420-打开CreateTable](https://doc.shiyanlou.com/courses/1738/1207281/431185671db986a7212ff7f9d813c4b1-0)

2）复制获取 JDBC 连接代码。程序中将加载 Hive JDBC 驱动，指定 Hive JDBC 的连接地址、用户名和密码创建 JDBC 连接并返回连接，创建数据库和创建映射表的实验步骤中会调用方法获取 JDBC 连接。

```java
try {
    // Load Hive JDBC driver
    Class.forName("org.apache.hive.jdbc.HiveDriver");
    // Create Hive JDBC connection
    connection = DriverManager.getConnection(
            "jdbc:hive2://sdbserver1:10000/"+database,// Hive JDBC connection url
            "sdbadmin",// Hive JDBC connection user name
            ""// Hive JDBC connection password (authentication is not enabled by default)
    );
} catch (ClassNotFoundException e) {
    e.printStackTrace();
} catch (SQLException e) {
    e.printStackTrace();
}
```

3）将获取 JDBC 连接代码粘贴至 CreateTable 类 getConnection 方法的 TODO code 2 注释区间内。

![1738-420-TODO2](https://doc.shiyanlou.com/courses/1738/1207281/a4ee28ee719ff4b7825e2c375fa8fb56-0)

代码块粘贴完毕后，完整代码如图所示：

![1738-420-DONE2](https://doc.shiyanlou.com/courses/1738/1207281/c8d7318bf4ec0dbad11e68ed6282fe63-0)

4）复制释放 JDBC 资源代码。程序中将接收 ResultSet、Statement 和 Connection 对象，若对象不为空则将其关闭。在创建数据库或创建映射表完成后将调用方法释放 JDBC 资源。

```java
try {
    // Release ResultSet
    if (resultSet != null) {
        resultSet.close();
    }
    // Release Statement
    if (statement != null) {
        statement.close();
    }
    // Release Connection
    if (connection != null) {
        connection.close();
    }
} catch (SQLException e) {
    e.printStackTrace();
}
```

5）将释放 JDBC 资源代码粘贴至 CreateTable 类 releaseSource 方法的 TODO code 3 注释区间内。

![1738-420-TODO3](https://doc.shiyanlou.com/courses/1738/1207281/5285415c91c440934ccb72561422ae14-0)

代码块粘贴完毕后，完整代码如图所示：

![1738-420-DONE3](https://doc.shiyanlou.com/courses/1738/1207281/2bf9bbe1d636683c3200f99fce4bba6e-0)

6）复制创建数据库代码。程序中将调用 getConnection 方法获取 JDBC 连接，并创建 Statement 对象执行创建sample 库的 SQL 语句。sample 库创建完成后程序将查询所有库并打印结果集。最终调用 releaseSource 释放 JDBC 资源。

```java
// Get Hive JDBC connection
Connection connection = getConnection("default");
// Initialize Statement
Statement statement = null;
// Initialize ResultSet
ResultSet resultSet = null;
try {
    // SQL statement of create database
    String createDatabaseSQL = "CREATE DATABASE IF NOT EXISTS " + databaseName;
    // Create Statement
    statement = connection.createStatement();
    // Execute the SQL statement of create database
    statement.execute(createDatabaseSQL);
    // View the database statement
    String showDatabases = "SHOW DATABASES";
    // Execute the view database statement to get the result set
    resultSet = statement.executeQuery(showDatabases);
    // Call the predefined result set to beautify the utility class and print the result set
    ResultFormat.printResultSet(resultSet);
} catch (SQLException e) {
    e.printStackTrace();
} finally {
    // Release Statement and Connection source
    releaseSource(resultSet, statement, connection);
}
```

> **说明**
>
> ResultFormat 工具类为已经封装好的查询结果集打印类，用于美化结果集的打印。封装的工具类在此不做赘述。

7）将创建数据库代码粘贴至 CreateTable 类 createDatabase 方法的 TODO code 4 注释区间内。

![1738-420-TODO4](https://doc.shiyanlou.com/courses/1738/1207281/eb2021c6315bc2dcac5db7491ef0604f-0)

代码块粘贴后如图所示（为展示效果已将 try 语句块折叠）：

![1738-420-DONE4](https://doc.shiyanlou.com/courses/1738/1207281/c1043d5860a9ba08e995967ed780143f-0)

8）右键点击 CreateTableMainTest 类，选择 Create/Edit CreateTableMainTest.main() 编辑主函数参数。

![1738-420-选择编辑1](https://doc.shiyanlou.com/courses/1738/1207281/42f8e64a41e4b3adc95642ed023cb0e1-0)

9）编辑主函数参数为 createdatabase。

![1738-420-编辑参数2](https://doc.shiyanlou.com/courses/1738/1207281/127546c684397cb4c1bb2a5f3c69e44b-0)

10）右键点击 CreateTableMainTest 类，选择 Run CreateTableMainTest.main() 运行程序。

![1738-420-运行1](https://doc.shiyanlou.com/courses/1738/1207281/01d549fa820dc82a23e92b751f597384-0)

11）查看运行结果。

![1738-420-结果2](https://doc.shiyanlou.com/courses/1738/1207281/10ef00db771b32e4f10de8df363bbb9b-0)

可以看到除了原有的 default 库外，新建的 sample 库也在查询所有数据库的结果集中。

## 映射 SequoiaDB 集合

#### 概述

在 Spark 中创建 SequoiaDB 集合的映射表需要指定映射目标集合所在的集合空间名、集合名以及 SequoiaDB 的数据库用户名和密码。若源表中已有数据，则无需定义表结构，在映射时 Spark 会根据结构化数据源自动生成表结构。

建表语法及参数说明如下（详见[巨杉官方文档](http://doc.sequoiadb.com/cn/sequoiadb-cat_id-1432190712-edition_id-0)）：

> CREATE TABLE employee
>
> USING com.sequoiadb.spark       -- 使用 SequoiaDB 的 Spark 连接驱动
>
> OPTIONS(
>
> ​	host 'sdbserver1:11810',           -- 访问 SequoiaDB 使用的主机名和协调节点
>
> ​	collectionspace 'sample',          -- 映射集合所在的集合空间名
>
> ​	collection 'employee',                -- 映射集合名
>
> ​	user 'sdbadmin',                         -- 用户名
>
> ​	password 'sdbadmin'                 -- 密码
>
> );

程序中将通过 JDBC 执行建表 SQL 语句在 Spark SQL 中创建 SequoiaDB 集合的映射表。

#### 操作步骤

1）打开 CreateTable 类。

![1738-420-打开CreateTable](https://doc.shiyanlou.com/courses/1738/1207281/431185671db986a7212ff7f9d813c4b1-0)

2）复制创建映射表程序代码。程序中将调用 getConnection 方法获取 JDBC 连接，使用 JDBC 连接创建 Statement 执行创建映射表 SQL 语句，建表完成后将查询映射表的表结构和数据内容，并将查询结果集打印至控制台。所有数据操作执行完毕后将释放 JDBC 资源。

```java
// Get Hive JDBC connection
Connection connection = getConnection("sample");
// Initialize Statement
Statement statement = null;
// Initialize ResultSet
ResultSet resultSet = null;
try {
    // Create Statement
    statement = connection.createStatement();
    // Drop the existing employee table
    String dropTable =
            "DROP TABLE IF EXISTS employee";
    // Execute the SQL statement of drop table
    statement.execute(dropTable);
    // Create a mapping table for the employee collection
    String mappingTable =
            "CREATE TABLE employee " +
                    "USING com.sequoiadb.spark  " +
                    "OPTIONS( " +
                    "host 'sdbserver1:11810', " +
                    "collectionspace 'sample', " +
                    "collection 'employee', " +
                    "user 'sdbadmin'," +
                    "password 'sdbadmin'" +
                    ")";
    // Execute the SQL statement of create mapping table
    statement.execute(mappingTable);
    // Get the structure of mapping table
    String getDesc =
            "DESC employee";
    // Execute the SQL statement of getting mapping table structure to get the result set
    resultSet = statement.executeQuery(getDesc);
    // Call the predefined result set to beautify the utility class and print the result set
    System.out.println("Printing table structure...");
    ResultFormat.printResultSet(resultSet);
    // Get the data of mapping table
    String queryTable = "SELECT * FROM employee";
    // Execute the SQL statement of get mapping table data to get the result set
    resultSet = statement.executeQuery(queryTable);
    // Call the predefined result set to beautify the utility class and print the result set
    System.out.println("Printing query result set...");
    ResultFormat.printResultSet(resultSet);
} catch (SQLException e) {
    e.printStackTrace();
} finally {
    // Release JDBC source
    releaseSource(resultSet, statement, connection);
}
```

> **说明**
>
> ResultFormat 工具类为已经封装好的查询结果集打印类，用于美化结果集的打印。封装的工具类在此不做赘述。

3）将创建数据库代码粘贴至 CreateTable 类 createTable 方法的 TODO code 5 注释区间内。

![1738-420-TODO5](https://doc.shiyanlou.com/courses/1738/1207281/d0a1fd45bfd6d1f46e9f488214f84f58-0)

代码块粘贴后如图所示（为展示效果已将 try 代码块折叠）：

![1738-420-DONE5](https://doc.shiyanlou.com/courses/1738/1207281/3f41580ce344093f2e49c85bb0b88d44-0)

4）右键点击 CreateTableMainTest 类，选择 Create/Edit CreateTableMainTest.main() 编辑主函数参数。

![1738-420-选择编辑1](https://doc.shiyanlou.com/courses/1738/1207281/42f8e64a41e4b3adc95642ed023cb0e1-0)

5）编辑主函数参数为 createtable。

![1738-420-编辑参数3](https://doc.shiyanlou.com/courses/1738/1207281/8a3c9eb7dbaf6f830aef65a7194b3f98-0)

6）右键点击 CreateTableMainTest 类，选择 Run CreateTableMainTest.main() 运行程序。

![1738-420-运行1](https://doc.shiyanlou.com/courses/1738/1207281/01d549fa820dc82a23e92b751f597384-0)

7）查看运行结果。

![1738-420-结果3](https://doc.shiyanlou.com/courses/1738/1207281/f1a082c020f4e3ad18437d61feb71ef0-0)

从映射表的表结构可以看出，在 Spark SQL 映射有数据的 employee 集合时，会自动匹配映射表各个字段相应的数据类型。

## 总结

本课程介绍了如何通过 MySQL 实例初始化 SequoiaDB 集合的数据，以及如何通过 JDBC 在 Spark SQL 中创建数据库和创建有记录的 SequoiaDB 集合的映射表。在 Spark SQL 中创建 SequoiaDB 集合的映射表时，Spark 会自动生成映射表的表结构。
