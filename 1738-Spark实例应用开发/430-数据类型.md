---
show: step
version: 1.0 
---

## 1 课程介绍

本课程将介绍 Spark SQL 支持的一些常见数据类型，以及 Spark SQL 数据类型和 SequoiaDB 数据类型的映射关系。实验过程中将通过 jdbc 在 Hive on Spark 中创建 SequoiaDB 的关联表，并插入不同类型的数据，观察不同数据类型分别在 Spark SQL 和 SequoiaDB 中的兼容情况。

#### 1.1  实验环境

当前实验的系统和软件环境如下：

* Ubuntu 16.04.6 LTS
* jdk version "1.8.0_242"
* spark version: 2.4.3
* SequoiaDB version: 5.0
* SequoiaSQL-MySQL version: 3.4
* IntelliJ IDEA Community Version: 2019.3.4

#### 1.2 知识点

#### 1.2.1 数据类型映射关系

| SequoiaDB 类型 | SparkSQL 类型 | SQL 实例类型            |
| -------------- | ------------- | ----------------------- |
| int32          | IntegerType   | int                     |
| int64          | LongType      | bigint                  |
| double         | DoubleType    | double                  |
| decimal        | DecimalType   | decimal                 |
| string         | StringType    | string                  |
| ObjectId       | StringType    | string                  |
| boolean        | BooleanType   | boolean                 |
| date           | DateType      | date                    |
| timestamp      | TimestampType | timestamp               |
| binary         | BinaryType    | binary                  |
| null           | NullType      | null                    |
| BSON(嵌套对象) | StructType    | struct < field:type,… > |
| array          | ArrayType     | array < type >          |

* 数组类型

  Spark 的 **ArrayType** 数据类型为由 elementType 类型元素组成的序列值。指定字段类型为 ArrayType 写法如下：

  ```sql
  字段名 array<数组元素类型>
  ```

* 结构化类型

  Spark 的 **StructType** 数据类型为一个拥有 **StructFields** (fields) 序列结构的值，StructField(name, dataType, nullable) 代表 StructType 中的一个字段，字段的名字通过 name 指定，dataType 指定field的数据类型，nullable 表示字段的值是否有null值。指定字段类型为 StructType 写法如下：

  ```sql
  字段名 struct<key:key类型,val:value类型>
  ```

  > 说明
  >
  > StructType 类型中可以嵌套其他类型，例如：
  >
  > ```sql
  > StructType struct<key:int,val:array<int>>
  > ```

#### 1.2.2 直接访问 SequoiaDB

在使用 Hive on Spark 时除了像第 2 章那样通过关联 MySQL 实例间接访问 SequoiaDB 外，还可以通过 SequoiaDB-Spark 连接器直接访问 SequoiaDB。以本实验中使用的 typelist 表为例：

![1738-430-01](https://doc.shiyanlou.com/courses/1738/1207281/55148046c8d833d3d49cceb475d49064-0)

SequoiaDB 中的集合对象（collection）本身是 `NoSQL` 的，所以如果想要通过 Spark SQL 关联 SequoiaDB 操作结构化数据，需要在建立表关联时定义表结构。

```sql
create table typelist(                       -- 定义表结构
IntegerType int,
LongType bigint,
DoubleType double,
DecimalType decimal(10,1),
StringType string,
BooleanType boolean,
DateType date,
TimestampType timestamp,
BinaryType binary,
ArrayType array<int>,
StructType struct<key:int,val:array<int>>    
) using com.sequoiadb.spark                  -- 使用 SequoiaDB-Spark 连接器
options(
host 'master:11810',                         -- 指定主机和节点
collectionspace 'sample',                    -- 指定集合空间
collection 'typelist'                        -- 指定集合
);
```

> 使用连接器需要确保 `$SPARK_HOME` 的 `jars` 目录下有 `spark-sequoiadb` jar 包

## 2 Maven 工程介绍

* 打开 SCDD-Spark 工程

  ![1738-430-02](https://doc.shiyanlou.com/courses/1738/1207281/d162c144755ed9c1b63bf539a7562d21-0)

* 当前实验使用到的 Maven 依赖

  ```xml
          <dependency>
              <!-- hive 的 jdbc 连接依赖 -->
              <groupId>org.apache.hive</groupId>
              <artifactId>hive-jdbc</artifactId>
              <version>1.2.1</version>
          </dependency>
  
          <dependency>
              <!-- SequoiaDB java 连接器 -->
              <groupId>com.sequoiadb</groupId>
              <artifactId>sequoiadb-driver</artifactId>
              <version>3.2.1</version>
          </dependency>
  
          <dependency>
              <!-- json 解析依赖 -->
              <groupId>com.alibaba</groupId>
              <artifactId>fastjson</artifactId>
              <version>1.2.58</version>
          </dependency>
  ```
  
* 打开当前实验所在包

  ![1738-430-03](https://doc.shiyanlou.com/courses/1738/1207281/5b46042c734108f1225d10e6d342f202-0)

## 3 程序样例

#### 3.1 关联 SequoiaDB 集合代码

在 Spark SQL 中创建表和 SequoiaDB *已有集合* 关联

```java
        // drop 已有的 typelist 表
        String dropTable="drop table if exists typelist";
        // 调用 HiveUtil 工具执行 sql
        HiveUtil.doDDL(dropTable);
        // 创建 SequoiaDB 集合的关联表
        String linkCollection=
                "create table typelist(\n" +
                        "IntegerType int,\n" +
                        "LongType bigint,\n" +
                        "DoubleType double,\n" +
                        "DecimalType decimal(10,1),\n" +
                        "StringType string,\n" +
                        "BooleanType boolean,\n" +
                        "DateType date,\n" +
                        "TimestampType timestamp,\n" +
                        "BinaryType binary,\n" +
                        "ArrayType array<int>,\n" +
                        "StructType struct<key:int,val:array<int>>\n" +
                        ") using com.sequoiadb.spark \n" +
                        "options(\n" +
                        "host 'master:11810',\n" +
                        "collectionspace 'sample',\n" +
                        "collection 'typelist'\n" +
                        ")";
        // 调用 HiveUtil 工具执行 sql
        HiveUtil.doDDL(linkCollection);
```

将上述代码粘贴至 LinkCollection 类的 `!TODO -- lesson3_datatype:step1` 标签处

![1738-430-04](https://doc.shiyanlou.com/courses/1738/1207281/e208abe4b07e2e7d87726ed0d7b80a04-0)

#### 3.2 插入记录代码

向 Spark 的 typelist 表中插入包含不同数据类型的记录

```java
        // 插入记录（不同类型字段）
        String insertSql =
                "insert into typelist\n" +
                        "values(\n" +
                        "1,\n" +
                        "9223372036854775807,\n" +
                        "3.1415,\n" +
                        "3.14,\n" +
                        "\"abc\",\n" +
                        "true,\n" +
                        "current_date(),\n" +
                        "current_timestamp(),\n" +
                        "encode(\"qazwsxedc\",\"UTF-8\"),\n" +
                        "array(1,2,3),\n" +
                        "struct(123,array(1,2,3))\n" +
                        ")";
        // 调用 HiveUtil 工具累执行 sql 语句
        HiveUtil.doDML(insertSql);
```

将上述代码粘贴至 DataOperation 类的 `!TODO -- lesson3_datatype:step3` 标签处

![1738-430-05](https://doc.shiyanlou.com/courses/1738/1207281/e49e11ea424cfcbe0da8a3301349c5ae-0)

## 4 运行程序

* #### 右键点击 Entry 类选择 Edit 主函数入参

  ![1738-430-06](https://doc.shiyanlou.com/courses/1738/1207281/4bcdffc05504116d01856c976261a340-0)

* #### 配置主函数入参为 `lesson3 datatype`

  ![1738-430-07](https://doc.shiyanlou.com/courses/1738/1207281/f67729a6f099ef4a13cc8e32a87c59cf-0)

* ####  右键点击 Entry 类 选择 Run 运行程序

  ![1738-430-08](https://doc.shiyanlou.com/courses/1738/1207281/2ada68eaaa324d1d6bf4eacec0f39af7-0)

* #### 程序运行结果

  ![1738-430-09](https://doc.shiyanlou.com/courses/1738/1207281/416733e5e95819d06a5f893e5f756fe7-0)

  记录在 SequoiaDB 引擎中是以 BSON 对象的形式存储，为了更清晰地展示查询效果这里做了格式化打印的处理。可以看到 2.1 中列举出来的各种数据类型分别 Spark 和 SequoiaDB 中的兼容情况。

## 5 总结

通过本课程的学习我们了解了 Spark SQL 常见的数据类型以及它们和 SequoiaDB 支持的数据类型的映射关系，并通过实验创建外表的形式直接访问 SequoiaDB 集合数据来查看 Spark 和 SequoiaDB 中的支持不同数据类型的能力。
